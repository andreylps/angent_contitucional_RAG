#!/usr/bin/env python3
"""
ConfiguraÃ§Ãµes centralizadas do sistema RAG JurÃ­dico

Facilita ajustes de performance, modelos e parÃ¢metros
"""

import os
from dataclasses import dataclass
from pathlib import Path

from dotenv import load_dotenv
from pydantic import SecretStr

# Carrega .env
load_dotenv()


@dataclass
class LLMConfig:
    """ConfiguraÃ§Ãµes de LLM"""

    # Modelo principal
    model: str = "gpt-4o-mini"
    temperature: float = 0.1
    max_tokens: int = 2000

    # Modelo para tarefas especÃ­ficas
    router_model: str = "gpt-4o-mini"  # Pode usar modelo mais barato
    summary_model: str = "gpt-4o-mini"

    # API
    api_key: SecretStr = os.getenv("OPENAI_API_KEY", "")  # type: ignore  # noqa: PGH003, RUF009

    # Rate limiting
    max_retries: int = 3
    timeout: int = 60


@dataclass
class EmbeddingsConfig:
    """ConfiguraÃ§Ãµes de embeddings"""

    # Modelo
    model: str = "text-embedding-3-small"  # RÃ¡pido e barato
    # model: str = "text-embedding-3-large"  # Mais preciso mas caro

    # DimensÃµes (3-small: 1536, 3-large: 3072)
    dimensions: int = 1536

    # Batch size para processar embeddings
    chunk_size: int = 1000

    # Cache
    use_cache: bool = True


@dataclass
class ChunkingConfig:
    """ConfiguraÃ§Ãµes de chunking de documentos"""

    # Tamanho dos chunks (em caracteres)
    chunk_size: int = 1000
    chunk_overlap: int = 200

    # Separadores hierÃ¡rquicos
    separators: list[str] | None = None

    def __post_init__(self):  # noqa: ANN204
        if self.separators is None:
            # Separadores jurÃ­dicos especÃ­ficos
            self.separators = [
                "\n\n## ",  # SeÃ§Ãµes
                "\n\nArt. ",  # Artigos
                "\n\n",  # ParÃ¡grafos
                "\n",  # Linhas
                " ",  # Palavras
                "",  # Caracteres
            ]

    # Metadata enrichment
    add_section_metadata: bool = True
    extract_article_numbers: bool = True


@dataclass
class RetrievalConfig:
    """ConfiguraÃ§Ãµes de retrieval"""

    # NÃºmero de documentos a retornar
    top_k: int = 5

    # Retrieval hÃ­brido
    use_hybrid: bool = True
    bm25_weight: float = 0.4
    vector_weight: float = 0.6

    # RRF (Reciprocal Rank Fusion)
    use_rrf: bool = True  # Recomendado!
    rrf_k: int = 60  # Constante RRF

    # Fetch mais documentos internamente para re-ranking
    fetch_k: int = 20

    # Re-ranking
    use_reranking: bool = False  # Ativa quando tiver cross-encoder
    reranker_model: str = "cross-encoder/ms-marco-MiniLM-L-6-v2"
    rerank_top_k: int = 3


@dataclass
class RouterConfig:
    """ConfiguraÃ§Ãµes do router agent"""

    # Modo de roteamento
    mode: str = "semantic"  # "keyword" ou "semantic"

    # Threshold para seleÃ§Ã£o de agentes
    confidence_threshold: float = 0.3

    # NÃºmero mÃ¡ximo de agentes a ativar simultaneamente
    max_agents: int = 2

    # Fallback para todos os agentes se confianÃ§a baixa
    fallback_to_all: bool = False


@dataclass
class CacheConfig:
    """ConfiguraÃ§Ãµes de cache"""

    # Ativar cache
    enabled: bool = True

    # DiretÃ³rio
    cache_dir: str = "cache"

    # TTL (Time To Live) em segundos
    ttl_seconds: int = 3600 * 24 * 7  # 7 dias

    # Tamanho mÃ¡ximo em MB
    max_size_mb: int = 500

    # Cache por tipo
    cache_embeddings: bool = True
    cache_queries: bool = True
    cache_responses: bool = True


@dataclass
class ChromaConfig:
    """ConfiguraÃ§Ãµes do ChromaDB"""

    # DiretÃ³rio
    persist_directory: str = "chroma_db"

    # Collections
    collections: dict[str, str] | None = None

    def __post_init__(self):  # noqa: ANN204
        if self.collections is None:
            self.collections = {
                "constitutional_law": "constitutional_docs",
                "consumer_law": "consumer_docs",
                "human_rights_law": "human_rights_docs",
            }


@dataclass
class SystemConfig:
    """ConfiguraÃ§Ã£o geral do sistema"""

    # Debug mode
    debug: bool = os.getenv("DEBUG_MODE", "false").lower() == "true"
    verbose: bool = False

    # Logs
    log_level: str = "INFO"  # DEBUG, INFO, WARNING, ERROR
    log_dir: str = "logs"

    # Performance
    enable_async: bool = True
    max_concurrent_agents: int = 3

    # Streaming
    enable_streaming: bool = False  # Para implementar depois


class Settings:
    """
    ConfiguraÃ§Ãµes centralizadas do sistema

    Uso:
        from config.settings import settings

        # Acessa configs
        model = settings.llm.model
        top_k = settings.retrieval.top_k
    """

    def __init__(self) -> None:
        self.llm = LLMConfig()
        self.embeddings = EmbeddingsConfig()
        self.chunking = ChunkingConfig()
        self.retrieval = RetrievalConfig()
        self.router = RouterConfig()
        self.cache = CacheConfig()
        self.chroma = ChromaConfig()
        self.system = SystemConfig()

    def validate(self) -> bool:
        """Valida configuraÃ§Ãµes"""
        errors = []

        # Verifica API key
        if not self.llm.api_key:
            errors.append("OPENAI_API_KEY nÃ£o encontrada no .env")

        # Verifica pesos do hybrid
        if self.retrieval.use_hybrid:
            total_weight = self.retrieval.bm25_weight + self.retrieval.vector_weight
            if abs(total_weight - 1.0) > 0.01:  # noqa: PLR2004
                errors.append(f"Pesos do hybrid devem somar 1.0, nÃ£o {total_weight}")

        # Verifica diretÃ³rios
        required_dirs = [
            self.cache.cache_dir,
            self.system.log_dir,
            self.chroma.persist_directory,
        ]

        for dir_path in required_dirs:
            Path(dir_path).mkdir(exist_ok=True, parents=True)

        if errors:
            print("âŒ Erros de configuraÃ§Ã£o:")
            for error in errors:
                print(f"   - {error}")
            return False

        print("âœ… ConfiguraÃ§Ãµes validadas com sucesso")
        return True

    def print_summary(self) -> None:
        """Imprime resumo das configuraÃ§Ãµes"""
        print("\n" + "=" * 60)
        print("âš™ï¸  CONFIGURAÃ‡Ã•ES DO SISTEMA RAG JURÃDICO")
        print("=" * 60)

        print("\nğŸ¤– LLM:")
        print(f"   Modelo: {self.llm.model}")
        print(f"   Temperature: {self.llm.temperature}")
        print(f"   Max Tokens: {self.llm.max_tokens}")

        print("\nğŸ“Š Embeddings:")
        print(f"   Modelo: {self.embeddings.model}")
        print(f"   DimensÃµes: {self.embeddings.dimensions}")
        print(f"   Cache: {'âœ…' if self.embeddings.use_cache else 'âŒ'}")

        print("\nâœ‚ï¸  Chunking:")
        print(f"   Chunk Size: {self.chunking.chunk_size}")
        print(f"   Overlap: {self.chunking.chunk_overlap}")

        print("\nğŸ” Retrieval:")
        print(f"   Top K: {self.retrieval.top_k}")
        print(f"   Modo: {'RRF' if self.retrieval.use_rrf else 'Weighted Hybrid'}")
        if self.retrieval.use_hybrid:
            print(
                f"   Pesos: BM25={self.retrieval.bm25_weight}, Vector={self.retrieval.vector_weight}"  # noqa: E501
            )
        print(f"   Re-ranking: {'âœ…' if self.retrieval.use_reranking else 'âŒ'}")

        print("\nğŸ¯ Router:")
        print(f"   Modo: {self.router.mode}")
        print(f"   Max Agentes: {self.router.max_agents}")

        print("\nğŸ’¾ Cache:")
        print(f"   Ativo: {'âœ…' if self.cache.enabled else 'âŒ'}")
        print(f"   TTL: {self.cache.ttl_seconds / 3600:.0f}h")
        print(f"   Max Size: {self.cache.max_size_mb}MB")

        print("\nğŸ—„ï¸  ChromaDB:")
        print(f"   DiretÃ³rio: {self.chroma.persist_directory}")
        print(
            f"   Collections: {len(self.chroma.collections) if self.chroma.collections else 0}"  # noqa: E501
        )

        print("\nğŸ”§ Sistema:")
        print(f"   Debug: {'âœ…' if self.system.debug else 'âŒ'}")
        print(f"   Async: {'âœ…' if self.system.enable_async else 'âŒ'}")
        print(f"   Log Level: {self.system.log_level}")

        print("=" * 60 + "\n")


# âœ¨ Singleton global
settings = Settings()


# âœ¨ EXEMPLO DE USO
if __name__ == "__main__":
    print("âš™ï¸  Teste das ConfiguraÃ§Ãµes")

    # Valida
    settings.validate()

    # Mostra resumo
    settings.print_summary()

    # Acessa valores especÃ­ficos
    print("\nğŸ“ Exemplos de uso:")
    print(f"   LLM Model: {settings.llm.model}")
    print(f"   Top K: {settings.retrieval.top_k}")
    print(f"   Cache ativo: {settings.cache.enabled}")

    # Modifica valores
    settings.retrieval.top_k = 10
    print(f"\nâœ… Top K modificado: {settings.retrieval.top_k}")
