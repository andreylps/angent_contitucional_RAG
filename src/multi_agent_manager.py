#!/usr/bin/env python3
"""
Gerenciador principal do sistema multiagente RAG jur√≠dico
"""

import asyncio
import os
import time
import uuid
from datetime import UTC, datetime
from typing import Any

from dotenv import load_dotenv
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI

# Carrega vari√°veis do .env
# Carrega vari√°veis do .env
load_dotenv()

# ‚úÖ CORRE√á√ÉO: Imports relativos sem "src."
from .agents.constitutional_agent import ConstitutionalAgent  # noqa: E402
from .agents.consumer_agent import ConsumerAgent  # noqa: E402
from .agents.human_rights_agent import HumanRightsAgent  # noqa: E402
from .agents.router_agent import LegalRouterAgent  # noqa: E402
from .pipelines.specialized_retrievers import (  # noqa: E402
    create_specialized_retriever,
)
from .utils.interaction_logger import log_interaction  # ‚úÖ v0.4: Importa o logger
from .utils.web_search_tool import (
    WebSearchTool,  # ‚úÖ v0.5: Importa a ferramenta de busca
)

# ‚úÖ v0.3.1: Template para re-escrever a pergunta com base no hist√≥rico (movido para o Manager)
REWRITE_QUERY_PROMPT = PromptTemplate(
    input_variables=["chat_history", "question"],
    template="""Dada a conversa a seguir e uma pergunta de acompanhamento, reformule a pergunta de acompanhamento para ser uma pergunta independente que possa ser entendida sem o hist√≥rico.

Hist√≥rico da Conversa:
{chat_history}

Pergunta de Acompanhamento: {question}

Pergunta Independente:""",
)

# ‚úÖ v0.5: Template para responder com base em busca na web (movido para o Manager)
WEB_ANSWER_PROMPT = PromptTemplate(
    input_variables=["context", "question"],
    template="""Voc√™ √© um assistente de IA. Sua tarefa √© responder √† pergunta do usu√°rio com base nos trechos de p√°ginas da web fornecidos no contexto.

**Instru√ß√µes OBRIGAT√ìRIAS:**
1.  **Baseie-se nos Fatos:** Responda APENAS com base no contexto fornecido (trechos da web). N√£o use conhecimento pr√©vio.
2.  **Cite a Fonte:** Ao final de cada informa√ß√£o relevante, cite a URL da fonte usando o formato `(Fonte: [URL])`.
3.  **Adicione um Aviso:** Ao final da sua resposta, inclua o seguinte aviso, exatamente como est√° escrito:
    "---
    **Aviso:** Esta resposta foi gerada com base em informa√ß√µes de fontes externas da web e n√£o da base de conhecimento jur√≠dica interna. Recomenda-se a valida√ß√£o das informa√ß√µes na fonte original."

Contexto da Web:
{context}

Pergunta: {question}

Resposta:""",
)


class MultiAgentManager:
    """Gerenciador principal que coordena todos os agentes especializados"""

    def __init__(self, model: str = "gpt-4o-mini") -> None:
        # ‚úÖ Verifica se API key existe no .env
        openai_api_key = os.getenv("OPENAI_API_KEY")

        if not openai_api_key:
            msg = "OPENAI_API_KEY n√£o encontrada no arquivo .env"
            raise ValueError(msg)

        # ‚úÖ CORRE√á√ÉO: ChatOpenAI pega API_KEY automaticamente do ambiente
        self.llm = ChatOpenAI(model=model, temperature=0.1)

        # Inicializa o router
        self.router = LegalRouterAgent(self.llm)

        # Inicializa os agentes especializados
        self.agents: dict[str, Any] = self._initialize_agents()

        # ‚úÖ v0.3: Adiciona um estado para armazenar o hist√≥rico da conversa
        self.conversation_history: list[dict[str, Any]] = []

        # ‚úÖ v0.5: Inicializa a ferramenta de busca na web e o prompt de resposta
        self.web_search_tool = WebSearchTool()
        self.web_answer_prompt = WEB_ANSWER_PROMPT

        print("‚úÖ MultiAgentManager inicializado com sucesso!")
        print("   - Router Agent: Pronto")
        print(f"   - Agentes especializados: {len(self.agents)} carregados")
        print(f"   - LLM: {model}")
        print(
            f"   - API Key: {'‚úÖ Carregada' if openai_api_key else '‚ùå N√£o encontrada'}"
        )

    def _initialize_agents(self) -> dict[str, Any]:
        """Inicializa todos os agentes especializados com seus retrievers"""
        agents: dict[str, Any] = {}

        try:
            # Agente Constitucional
            constitutional_retriever = create_specialized_retriever(
                "constitutional_law"
            )
            agents["constitutional_law"] = ConstitutionalAgent(
                domain="constitutional_law",
                retriever=constitutional_retriever,
                llm=self.llm,
            )
            print("   ‚úÖ ConstitutionalAgent carregado")

            # Agente Consumer
            consumer_retriever = create_specialized_retriever("consumer_law")
            agents["consumer_law"] = ConsumerAgent(
                domain="consumer_law", retriever=consumer_retriever, llm=self.llm
            )
            print("   ‚úÖ ConsumerAgent carregado")

            # Agente Human Rights
            human_rights_retriever = create_specialized_retriever("human_rights_law")
            agents["human_rights_law"] = HumanRightsAgent(
                domain="human_rights_law",
                retriever=human_rights_retriever,
                llm=self.llm,
            )
            print("   ‚úÖ HumanRightsAgent carregado")

        except Exception as e:
            print(f"‚ùå Erro ao inicializar agentes: {e}")
            raise

        return agents

    async def _rewrite_query_with_history(self, question: str) -> str:
        """Se houver hist√≥rico, re-escreve a pergunta para ser aut√¥noma."""
        if not self.conversation_history:
            return question

        print("   [Manager] Reescrevendo a pergunta com base no hist√≥rico...")

        # Formata o hist√≥rico para o prompt
        formatted_history = "\n".join(
            [f"{msg['role']}: {msg['content']}" for msg in self.conversation_history]
        )

        rewrite_chain = REWRITE_QUERY_PROMPT | self.llm | StrOutputParser()

        try:
            rewritten_question = await rewrite_chain.ainvoke(
                {"chat_history": formatted_history, "question": question}
            )
            print(f"   [Manager] Pergunta reescrita: '{rewritten_question}'")
            return rewritten_question
        except Exception as e:
            print(
                f"   ‚ö†Ô∏è [Manager] Erro ao reescrever pergunta: {e}. Usando a pergunta original."
            )
            return question

    async def process_query(self, query: str) -> dict[str, Any]:
        """
        Processa uma consulta usando o sistema multiagente

        Args:
            query: Pergunta do usu√°rio

        Returns:
            Dict com resposta completa e metadados
        """
        # ‚úÖ v0.4: Inicia o logging da intera√ß√£o
        interaction_id = str(uuid.uuid4())
        start_time = time.time()
        log_data: dict[str, Any] = {
            "interaction_id": interaction_id,
            "timestamp_utc": datetime.now(UTC).isoformat(),
            "original_query": query,
        }

        print(f"üîç Processando consulta: '{query}'")

        try:
            # 1. ‚úÖ v0.3.1: Reescreve a pergunta ANTES do roteamento
            standalone_query = await self._rewrite_query_with_history(query)

            # 2. Roteamento - decide quais agentes usar com base na pergunta completa
            log_data["standalone_query"] = standalone_query
            routing_decision = self.router.get_routing_decision(standalone_query)
            print(f"   üéØ Roteamento: {routing_decision['selected_agents']}")
            print(f"   üìä Scores: {routing_decision['domain_scores']}")

            # ‚úÖ AJUSTE: Tratamento cordial para perguntas fora de contexto
            # Se o roteador identificar que a pergunta est√° fora do escopo,
            # retorna uma resposta amig√°vel e encerra o processamento.
            if routing_decision["selected_agents"] == ["out_of_context"]:
                print(
                    "   ‚ö†Ô∏è Pergunta fora de contexto detectada. Acionando busca na web..."
                )
                final_response = await self._handle_web_search(standalone_query, query)
                log_data.update(final_response)
                return final_response

            # 3. Executa os agentes selecionados
            agent_responses = await self._execute_agents(
                standalone_query, routing_decision["selected_agents"]
            )

            # 4. Combina resultados
            final_response = self._combine_responses(
                query, agent_responses, routing_decision
            )

            # ‚úÖ v0.3: Atualiza o hist√≥rico da conversa com a nova intera√ß√£o
            self.conversation_history.append({"role": "user", "content": query})
            self.conversation_history.append(
                {"role": "assistant", "content": final_response["final_answer"]}
            )

            print(
                f"   ‚úÖ Consulta processada - {len(agent_responses)} agente(s) responderam"  # noqa: E501
            )
            log_data.update(final_response)
            return final_response  # noqa: TRY300

        except Exception as e:  # noqa: BLE001
            print(f"‚ùå Erro no processamento: {e}")
            error_response = self._create_error_response(query, str(e))
            log_data.update(error_response)
            return error_response
        finally:
            # ‚úÖ v0.4: Finaliza e registra o log da intera√ß√£o
            end_time = time.time()
            log_data["duration_seconds"] = round(end_time - start_time, 2)
            log_interaction(log_data)

    def clear_history(self) -> None:
        """Limpa o hist√≥rico da conversa."""
        self.conversation_history = []
        print("   üßπ Hist√≥rico da conversa limpo.")

    async def _execute_agents(
        self, query: str, selected_agents: list[str]
    ) -> list[dict[str, Any]]:
        """Executa os agentes selecionados em paralelo"""
        tasks = []

        for domain in selected_agents:
            agent = self.agents.get(domain)
            if agent:
                # ‚úÖ v0.3: Passa o hist√≥rico da conversa para o agente
                # Executa cada agente
                task = (
                    asyncio.create_task(  # ‚úÖ CORRE√á√ÉO: Usa self.conversation_history
                        self._run_agent_safe(agent, query, self.conversation_history)
                    )
                )
                tasks.append(task)

        # Aguarda todas as respostas
        responses = await asyncio.gather(*tasks, return_exceptions=True)

        # Filtra respostas v√°lidas
        valid_responses: list[dict[str, Any]] = []
        for response in responses:
            if isinstance(response, dict) and response.get("status") == "success":
                valid_responses.append(response)
            elif isinstance(response, Exception):
                print(f"   ‚ö†Ô∏è Agente falhou: {response}")

        return valid_responses

    async def _run_agent_safe(
        self,
        agent: Any,
        query: str,
        conversation_history: list[dict[str, Any]],
    ) -> dict[str, Any]:
        """Executa um agente com tratamento de erro"""
        try:
            # ‚úÖ v0.3: Passa a query e o hist√≥rico para o agente.
            return await agent.invoke(
                {
                    "query": query,  # Esta √© a standalone_query
                    "original_query": conversation_history[-1]["content"]
                    if conversation_history
                    else query,  # Passa a √∫ltima pergunta do usu√°rio
                    "conversation_history": conversation_history,
                }
            )
        except Exception as e:  # noqa: BLE001
            return {
                "agent": agent.name,
                "agent_domain": agent.domain,  # ‚úÖ CORRE√á√ÉO: Usa o atributo correto do objeto agente.
                "answer": f"Erro no agente: {e!s}",
                "sources": [],
                "confidence": 0.0,
                "status": "error",
            }

    async def _handle_web_search(
        self, standalone_query: str, original_query: str
    ) -> dict[str, Any]:
        """Lida com a l√≥gica de fallback de busca na web."""
        web_results = self.web_search_tool.search(standalone_query)

        if not web_results:
            return {
                "query": original_query,
                "final_answer": "N√£o foram encontrados documentos relevantes para responder a esta pergunta, nem na base interna nem na web.",
                "sources": [],
                "primary_agent": "web_search_fallback",
                "confidence": 0.1,
                "status": "no_documents",
            }

        web_context = "\n\n---\n\n".join(
            [f"Fonte: {res['url']}\nConte√∫do: {res['content']}" for res in web_results]
        )
        web_chain = self.web_answer_prompt | self.llm | StrOutputParser()
        answer = await web_chain.ainvoke(
            {"context": web_context, "question": original_query}
        )
        sources = [res["url"] for res in web_results]

        return {
            "query": original_query,
            "final_answer": answer,
            "sources": sources,
            "primary_agent": "web_search_fallback",
            "agent_domain": "general",
            "confidence": 0.60,
            "all_responses": [],
            "status": "success_web_fallback",
        }

    def _combine_responses(
        self,
        query: str,
        agent_responses: list[dict[str, Any]],
        routing_decision: dict[str, Any],
    ) -> dict[str, Any]:
        """Combina as respostas dos agentes em uma resposta final"""

        if not agent_responses:
            return self._create_no_answer_response(query)

        if len(agent_responses) == 1:
            primary_response = agent_responses[0]
            return {
                "query": query,
                "final_answer": primary_response["answer"],
                "sources": primary_response["sources"],
                "primary_agent": primary_response["agent"],
                "agent_domain": primary_response["agent_domain"],
                "confidence": primary_response["confidence"],
                "routing_decision": routing_decision,
                "all_responses": agent_responses,
                "status": "success",
            }

        # L√≥gica para m√∫ltiplos agentes
        combined_answer = self._merge_multiple_answers(agent_responses)
        all_sources = [
            source for resp in agent_responses for source in resp.get("sources", [])
        ]

        return {
            "query": query,
            "final_answer": combined_answer,
            "sources": all_sources,
            "primary_agent": routing_decision["primary_agent"],
            "agent_domains": [resp["agent_domain"] for resp in agent_responses],
            "confidence": max(resp["confidence"] for resp in agent_responses),
            "routing_decision": routing_decision,
            "all_responses": agent_responses,
            "status": "success",
        }

    def _merge_multiple_answers(self, responses: list[dict[str, Any]]) -> str:
        """Combina respostas de m√∫ltiplos agentes"""
        if len(responses) == 1:
            return responses[0]["answer"]

        # Para m√∫ltiplas respostas, cria uma resposta integrada
        answer_parts: list[str] = ["üîç **An√°lise Multiagente - Resposta Integrada**\n"]

        for response in responses:
            answer_parts.append(f"**üèõÔ∏è {response['agent'].replace('_', ' ').title()}:**")
            answer_parts.append(response["answer"])
            answer_parts.append("---")

        answer_parts.append(
            "\n**üí° Conclus√£o Integrada:** Esta an√°lise combina perspectivas de m√∫ltiplas fontes jur√≠dicas para uma vis√£o completa."  # noqa: E501
        )

        return "\n".join(answer_parts)

    def _create_no_answer_response(self, query: str) -> dict[str, Any]:
        """Cria resposta quando nenhum agente consegue responder"""
        return {
            "query": query,
            "final_answer": "N√£o foi poss√≠vel encontrar uma resposta adequada nas bases jur√≠dicas especializadas.",  # noqa: E501
            "sources": [],
            "primary_agent": None,
            "confidence": 0.0,
            "routing_decision": None,
            "all_responses": [],
            "status": "no_answer",
        }

    def _create_error_response(self, query: str, error: str) -> dict[str, Any]:
        """Cria resposta de erro"""
        return {
            "query": query,
            "final_answer": f"Erro no sistema: {error}",
            "sources": [],
            "primary_agent": None,
            "confidence": 0.0,
            "routing_decision": None,
            "all_responses": [],
            "status": "error",
        }

    def get_agent_info(self) -> dict[str, Any]:
        """Retorna informa√ß√µes sobre os agentes dispon√≠veis"""
        return {
            "total_agents": len(self.agents),
            "available_agents": list(self.agents.keys()),
            "router_ready": hasattr(self, "router"),
            "llm_model": self.llm.model_name,
        }

    # M√©todo s√≠ncrono para facilitar o uso
    def process_query_sync(self, query: str) -> dict[str, Any]:
        """Vers√£o s√≠ncrona do process_query para facilitar o uso"""
        return asyncio.run(self.process_query(query))
